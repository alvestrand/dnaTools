# readme - for this folder

# Contents {{{

= scripts

* positives-and-no-calls.py
* redux.bash

= data

* - cladenames.txt - automagically generated SNP names can be subsituted
* - implications.txt - this allows you to correct for no calls and other problems in the data
*   (a) forcing that any test positive for a sub-clade must be positive for its parent
    (b) (i) can (and probably should) also include two different SNPs.
        (ii) enforces Z381+ if L48+ and U106+.
    (c) can also include a number of SNPs not found in any BigY test which need to be inserted
    (d) used to denote positives in the reference genome
* - badlist.txt - snp's that should be filtered out
* - recurrencies.txt - snp's that recur. sometimes useful, sometimes not.
* merge-ignore.txt
* age.bed
* poisson.tbl
* cpoisson.tbl

= ???

* events.svg

= web content

* treefoot.html

# }}}

# Iain's Goals

= PART A: Assemble the SNP data {{{

1. The records being stored on James's haplogroup-r.org database contain VCF+BED zipped files with associated meta-data. A check 
   needs to be made against this data and new files downloaded and unzipped. A data structure "Kits" references data structure 
   "People", as some people have more than one kit at one company. Kits contain information on the kit (number, company, coverage, etc.), 
   while people need to contain aggregated and meta-data for each person: MDKA latitude; longitude; MDKA date; MDKA date uncertainty; 
   MDKA text string; most-recent known haplogroup; shared testing coverage; shared testing coverage within age BED region; total testing 
   coverage.

2. VCF files need to be parsed for a list of variants.

3. This list of variants needs to be compared against a database (e.g. YBrowse's snps_hg38.csv) to identify ancestral/derived values 
   (replacing reference values).

4. The list of variants needs to be parsed to identify/standardise identical indels which are reported differently between tests.

5. Multiple kits (e.g. BigY+YElite) from the same person need identified and merged, and new VCF and BED structures created for them.

6. A data matrix (Calls) is needed, encoding kits and variants. For each entry, an array is needed showing: (a) postive/negative 
   assignment (b) positive/negative call, (c) called/uncalled, (d) read quality, (e) mapping quality, (f) read depth, 
   (g) within the age analysis BED regions.

7. The VCF files need to be parsed to recover (b), (d), (e) and (f) in Calls

8. The BED files need parsed to recover (c) in Calls.

9. Comparison to the age analysis BED file is needed to populate (g) in Calls.

10.Non-NGS tests can similarly be added to Calls, including those from YSeq, the literature, and SNP packs. For YSeq, or where 
   corresponding BED information is unavailable, no-calls must be inserted for non-positive variants.

}}}
= PART B: Assemble the tree {{{ 

1. Create a data structure (Tree) noting clade ID; parent ID; clade name; {list of variants}; {quality scores for phylogenic 
   accuracy}; {one or more flags for variants for later analysis}; {list of child clades}; {ancestral STR alleles}; 
   origin latitude; origin longitude; shared coverage; shared coverage within age BED; oldest/defining MDKA; SNP age; {SNP 
   age 95% confidence interval}; {SNP age probability distribution function [PDF] (e.g. in steps of 10 years)}; {SNP 
   parent clade age PDF}; STR age; {STR age 95% confidence interval}; {STR age PDF}; {STR parent clade age PDF}; combined 
   age; {combined age 95% confidence interval}; {combined age PDF},

2. Select mutations with 100% calls and make a tree:

(a) Sort Calls matrix vertically by variant to get the most-common SNPs to the top.
(b) Sort Calls horizontally by person to group people with common SNPs into clades.
(c) Form clades from square blocks of positive calls {Variants,People} in this 2D space.
(d) Assign positive calls as positive and negative calls as negative in Calls (hence assignment and call are redundant, 
    but the distinction is needed later).
(e) Identify members of these clades from People, associate Variants with a clade, and assign a parent and children to each clade.

3. Progress individually through progressively worse-called SNPs...

(a) Parse a list of manual implications, which dictate where positives can be implied from comparative clades (e.g. if a kit 
    is P310+ and L11 is uncalled, a positive is implied for L11).
(b) Parse a reject list, which manually removes bad mutations from the tree.
(c) Recognise if a mutation is clearly equivalent to an existing clade or clearly forms a new clade (e.g. if all positive 
    variants are P312+ but some U106+ tests or low-coverage (YSeq/pack) tests are uncalled, the no calls can be assigned as 
    negative).
(d) In ambiguous cases, identify all phylogenically possible locations in the tree, mark the variant as approximately 
    located in the quality score array, and probabilistically chose a location among them (e.g. a variant is most likely 
    located in a clade with more equivalent SNPs). Ambiguous singleton SNPs should be identified as such, not merged up, as  
    they will later not be counted by the age analysis.

4. Identify and merge MNPs. Also decide whether they are just poorly recorded complex indels.

5. Consult a reference list of named haplogroups (e.g. a text dump of FTDNA's haplotree) to assign a name to each clade in the Tree. 
   Otherwise, automatically assign one.

6. Assign oldest or defining MDKAs to nodes in Tree from People (likely with cross-reference to a manually curated list).

7. Assign most-recent known haplogroups to People.

8. Compute a coverage (BED / callableLoci) for each branch in Tree, and for each tester in People:

(a) The total testing coverage for People should be the coverage of their NGS test. In cases where more than one test is taken (e.g. 
    BigY+YElite, BigY+WGS, BigY+YSeq), the concatenation of tests should be used.
(b) The shared testing coverage for Tree nodes should be the count of the number of bases tested by two or more People under 
    that node. The most effective way to do this is to generate new BED files for each node of the tree.
(c) A *nix-style join should be done against the age analysis BED regions to determine the coverage used for the later age analysis.

9. Output a visual representation of the tree and sorted matrix of Calls.

}}}
= PART C: Importing STR matches {{{

1. A data structure (STRs) is needed, containing kit number; person; and a standardised array of STR results. Nulls must be representable.

2. The People array must be consulted to populate person in the STRs array.

3. A list of known ancestral STRs (e.g. U106, P312, P311) can be parsed to populate said array in the Tree structure.

4. The tree can be parsed from top to bottom, assigning ancestral STRs to each node. An effective way to do this seems to be to start 
   from the ancestral STRs from the parent clade, and assign mutations from this if two-thirds* of the sub-clades share this mutation (*not sure 
   if this should be >= or > 2/3). Exceptions to this can be managed in step 3.

5. Parse list of non-NGS testers, and match each up to a clade in a probabilistic (binomial) sense (cf. SAPP) using the identified 
   mutations in that clade.

}}}
= PART D: Geographical analysis {{{

1. Working from the bottom to the top of the Tree, combine the geographic origins of People into their most-recent known haplogroups. 
   Weighting here is important. First, each country/region needs weighted according to the depth of testing (regional weight = population 
   at average MRCA date / testing population). Haplogroups can then be combined, working up the tree:

(a) If a clade has no sub-clades, the nodal location is = {Sum(Latitude * regional weight)/Sum(regional weight) ; Sum(Longitude * 
    regional weight)/Sum(regional weight)}.
(b) If a clade has one or more sub-clades, the weight for each sub-clade should be multiplied by the square root of the number of testers 
    within it, then included in the sum in the same way. (The best choice of weight may need some adjustment from a square root, but that 
    would be a good first guess.)
(c) Update latitude and longitude of origin in Tree.

2. Output a series of visualisations allowing migrations to be tracked.

}}}
= PART E: Age analysis {{{

1. For each Person, use Calls and Tree to count the singletons and shared SNPs which are (a) within the BED file of each Person and (b) 
   within the regions of shared coverage for the most-recent known haplogroup.
2. For each NGS test, use Poisson statistics to derive an array representing the PDF for the age of that clade, and multiply the PDF 
   arrays together.
3. If the MRCA for that node can be limited or directly set by oldest/defining MDKAs in People, or from ancient DNA, the PDFs should 
   be limited accordingly.
4. Assign the PDF to Tree and work up to the top of the tree.
5. Work back down the tree, generating an array representing the PDF based on the parent of each clade. Store these separately in Tree 
   for now.
6. Repeat steps (2) to (5) for Y-STRs, using Walshs binomial method (best for pairs of people or step-wise measures) and/or Ken 
   Nordtvedt's inter-clade variance method (best for comparing groups of people).
7. Multiply the SNP and STR PDFs together; do the same for the parent SNP and STR PDFs.
8. Multiply the PDFs together with the parent PDFs to create final ages, 95% c.i.s and PDFs in Tree.
9. Output the final ages as lists and visualisations.

The final output will be a time-indexed, geo-coded haplogroup tree, which can be used to track relationships and migrations over the 
whole of the root haplogroup's history. The aim is to apply this to R-L11 and possibly a wider set of haplogroups.

}}}

